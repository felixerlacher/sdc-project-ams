{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/llm/ChatTable/new_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfelix-ml\u001b[0m (\u001b[33mfml-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/felix/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelWithLMHead, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import transformers\n",
    "import torch\n",
    "transformers.set_seed(42)\n",
    "\n",
    "import wandb\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "#CUDA_VISIBLE_DEVICES\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'just_finetuning_leo-hessianai.ipynb'\n",
    "wandb.login(key=\"247b3da94c9b88bd5e990f1d94799ca3ded57d6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSON file\n",
    "file_path = 'berufslexikon_cleaned_manual.json'\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset('json', data_files=file_path)\n",
    "\n",
    "# Specify the model checkpoint\n",
    "model_checkpoint = \"LeoLM/leo-hessianai-7b-chat\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '3D-DesignerIn \\n 3D-DesignerIn Berufsbereiche: Medien, Grafik, Design, Druck, Kunst, Kunsthandwerk Ausbildungsform: Uni/FH/PH Einstiegsgehalt lt. KV: Gehalt: € 2.210,- bis € 2.730,-  Tätigkeitsmerkmale 3D-DesignerInnen entwerfen, erstellen und programmieren komplexe, dreidimensionale digitale Objekte. Da sind z.B. Figuren für Videospiele und Filme, Grafiken, bewegte Bilder oder räumlich wirkende Darstellungen. Sie animieren auch Standbilder aus 3D-Scans. Außerdem programmieren sie interaktive 3D-Echtzeitgrafiken, zum Beispiel ein dreidimensionales Modell einer realen Szene (Virtuelle Realität).Digitale Objekte dienen zur Visualisierung in allen möglichen Bereichen wie Architektur, Raumplanung, Verkehr und Sport oder für die Visualisierung in technischen Bereichen. Die DesignerInnen nutzen 3D-Modeling-Software (z.B. AutoCad) und Simulationssoftware für interaktive 3D-Echtzeitgrafiken. Besondere Bedeutung hat die Visualisierung von Objekten auch für das E-Learning sowie für Orientierungssysteme, Modelabels und technische Dokumentationen.Typische Tätigkeiten sind z.B:Mitwirkung an der Entwicklung von Drehbüchern und StorylinesZeichnungen und Skizzen anfertigenModellieren von 3D-Objekten für Filme, Musikvideos oder ComputerspieleGestalten von Grafiken für Social Media KampagnenGestalten von 360-Grad-Videos für die Werbe- und SpielindustrieVisualisierung von Produkten für ProduktpräsentationenAnimieren von Figuren und ObjektenErstellen von virtuellen Räumen, Architektur- und Landschaftsvisualisierungen Siehe auch: MedieninformatikerIn (UNI/FH/PH) Industrial DesignerIn (UNI/FH/PH) Game DesignerIn (UNI/FH/PH) Anforderungen Eine innovative Ideenfindung und ein gewisses Maß an künstlerischer Begabung sind von Vorteil. Die Arbeiten erfolgen manchmal unter Zeitdruck, wobei KundInnen trotzdem eine detailorientierte Arbeit einfordern.Interesse an Technik: Bildverarbeitung, Audio- und VideotechnikBlick für DetailsGutes SehvermögenRasche AuffassungsgabeStrukturiertes ArbeitenRäumliches VorstellungsvermögenGutes Zeitmanagement\\xa0Je nach Branche sind auch andere Belange wichtig, etwa ein Interesse an Kunst, Kultur und Design (z.B. für Arbeiten in der Retail- oder Luxusgüter Industrie). Beschäftigungsmöglichkeiten 3D-DesignerInnen arbeiten in der Pre- und Postproduktion im Bereich Game Design (Storyboarding, Schnitt). Beschäftigungsmöglichkeiten eröffnen sich zum Teil in der Konsumgüterindustrie in einer Design-Abteilung oder im Umfeld der Marketing-Abteilung. Funktionales 3D-Design wird in fast jeder Branche angewandt, auch in den technischen Bereichen, in der Architektur, der Geoinformation und in der Unfallanalytik. Aufgabenfelder bestehen in den Unternehmen der unterschiedlichsten Branchen, z.B:Spezialisierte Design-BürosMultimedia-AgenturenSportartikehersteller: Markenlogos, WerbematerialGesundheitssektor: Animierte InfografikenIndustrie: Technische VisualisierungFahrzeugtechnik: Produkt-KonfiguratorenWerbebranche: Interaktive Werbeanzeigen, Online-WerbungSocial Media und Webdesign: Visuelle Konzepte für BlogsOnlinehandel: Interaktive ProduktpräsentationProduktdesign: Prototyp-VisualisierungArchitektur: Rundgänge, pysikalische Simulation von LichtMedizin: Funktionsweise von Werkzeugen verdeutlichenTourismus/Kultur: Interaktive Webkarten, virtuelle Museen Berufsaussichten Besondere Chancen zeichnen sich für die AbsolventInnen ab, die kombinierte Kenntnisse in Bezug auf Technik, Gestaltung und Organisation optimal einsetzen können. Vor allem ist die weltweite Nutzung von Virtual Reality (VR) stark gestiegen.Virtual Reality ist die blickpunktabhängige Echtzeitberechnung von 3D-Grafik (computergesteuerte Bilder in 3D). Das ermöglicht es, durch eine computergenerierte, künstliche räumliche Umgebung zu navigieren und mit dieser zu interagieren. Mit VR kann man z.B. üben, in einer Stresssituation eine Rede zu halten. Zum Unterschied von normaler Video-Technik werden für VR-Videos besondere Kameras benötigt, die aus verschiedensten Winkeln filmen. Im Unterschied dazu überlappt Augmented Reality (AR) das in der Wirklichkeit gesehene Bild oder Szene mit einer Simulation.Typische 3D-Anwendungen werden zunehmend auch in der Stadtplanung eingesetzt sowie in der Außen- und Innenarchitektur und Möbelausstattung. In der 3D-Realität können auch Veränderungen vorab visualisiert, analysiert und optimiert werden.3D-Design steht in Zusammenhang mit Game Design und spielt verstärkt auch bei Themen wie Business Communications oder Einsatzkräftetraining für Feuerwehren und Katastrophendienste eine Rolle. Aktuelles Update zu Berufsaussichten:   \"GrafikerIn\", dem der Beruf \"3D-DesignerIn\" zugeordnet ist. Ausbildung 3D-Design ist eine Kombination aus Kunst und Technik visuelles Design und Videobearbeitung. Eine Grundlage kann z.B. ein Studium im Bereich Game-Design, Grafikdesign (Motion Graphics), Multimedia Design oder Mediendesign bieten. Beispiele für Ausbildungen:Medieninformatik und Visual Computing (Bachelor): TU WienMedientechnik und –design (Bachelor): FH Oberösterreich Game Engineering und Simulation (Master): FH Technikum Wien Game Art & 3D Animation (Diploma): SAE Institute WienVisual Effects Animation (Bachelor with Honours): SAE Institute Wien Digital Art–Compositing (Master): Uni für Musik und darstellende Kunst, Wien Ergebnisse aus dem Ausbildungskompass: Kärnten Ausbildung Tabelle Universitätsstudium Game Studies and Engineering (öffnen)Masterstudium (UNI) Universität Klagenfurt - Alpen-Adria-Universität Klagenfurt (öffnen) 9020 Klagenfurt am Wörthersee, Universitätsstraße 65-67 Tel.: +43 463 2700, https://www.aau.at/ Niederösterreich Ausbildung Tabelle Fachhochschulstudium Creative Computing (öffnen)Bachelorstudium (FH) Fachhochschule St. Pölten GmbH (öffnen) 3100 St. Pölten, Campus-Platz 1 Tel.: +43 (0)2742 / 313 228 -200, https://www.fhstp.ac.at Ausbildung Tabelle Universitätsstudium Grafik- und Informationsdesign (öffnen)Bachelorstudium (UNI) New Design University Privatuniversität (öffnen) 3100 St. Pölten, Mariazeller Straße 97a Tel.: +43 (0)2742 / 851 24180, https://www.ndu.ac.at/ Ausbildung Tabelle Fachhochschulstudium Digital Media Production (öffnen)Masterstudium (FH) Fachhochschule St. Pölten GmbH (öffnen) 3100 St. Pölten, Campus-Platz 1 Tel.: +43 (0)2742 / 313 228 -200, https://www.fhstp.ac.at Ausbildung Tabelle Universitätsstudium Innenarchitektur & Visuelle Kommunikation (öffnen)Masterstudium (UNI) New Design University Privatuniversität (öffnen) 3100 St. Pölten, Mariazeller Straße 97a Tel.: +43 (0)2742 / 851 24180, https://www.ndu.ac.at/ Oberösterreich Ausbildung Tabelle Fachhochschulstudium Digital Arts (öffnen)Bachelorstudium (FH) Fachhochschule Oberösterreich - Informatik, Kommunikation, Medien - Campus Hagenberg (öffnen) 4232 Hagenberg, Softwarepark 11 Tel.: +43 (0)5 0804 20, Fax: +43 (0)5 0804 21599, https://www.fh-ooe.at/campus-hagenberg/ Ausbildung Tabelle Universitätsstudium Industrial Design (öffnen)Bachelorstudium (UNI) Kunstuniversität Linz (öffnen) 4010 Linz, Hauptplatz 6 Tel.: +43 (0)732 / 78 98 -0, https://www.ufg.at/ Ausbildung Tabelle Universitätsstudium Raum & Designstrategien (öffnen)Bachelorstudium (UNI) Kunstuniversität Linz (öffnen) 4010 Linz, Hauptplatz 6 Tel.: +43 (0)732 / 78 98 -0, https://www.ufg.at/ Ausbildung Tabelle Universitätsstudium Industrial Design (öffnen)Masterstudium (UNI) Kunstuniversität Linz (öffnen) 4010 Linz, Hauptplatz 6 Tel.: +43 (0)732 / 78 98 -0, https://www.ufg.at/ Ausbildung Tabelle Universitätsstudium Raum & Designstrategien (öffnen)Masterstudium (UNI) Kunstuniversität Linz (öffnen) 4010 Linz, Hauptplatz 6 Tel.: +43 (0)732 / 78 98 -0, https://www.ufg.at/ Ausbildung Tabelle Universitätsstudium Visuelle Kommunikation - Grafikdesign & Fotografie (öffnen)Masterstudium (UNI) Kunstuniversität Linz (öffnen) 4010 Linz, Hauptplatz 6 Tel.: +43 (0)732 / 78 98 -0, https://www.ufg.at/ Salzburg Ausbildung Tabelle Fachhochschulstudium Design & Produktmanagement (öffnen)Masterstudium (FH) FH Salzburg - Campus Kuchl (öffnen) 5431 Kuchl, Markt 136a Tel.: +43 / 50-2211-2000, Fax: +43 / 50-2211-2099, https://www.fh-salzburg.ac.at Ausbildung Tabelle Fachhochschulstudium Human-Computer Interaction (öffnen)Masterstudium (FH) FH Salzburg - Campus Urstein (öffnen) 5412 Puch/Salzburg, Urstein Süd 1 Tel.: +43 / 50-2211-0, https://www.fh-salzburg.ac.at/ Universität Salzburg - Paris Lodron Universität Salzburg (öffnen) 5020 Salzburg, Kapitelgasse 4-6 Tel.: +43 (0)662 / 80 44 -0, Fax: +43 (0)662 / 80 44 -145, https://www.plus.ac.at/ Ausbildung Tabelle Fachhochschulstudium Realtime Art & Visual Effects (öffnen)Masterstudium (FH) FH Salzburg - Campus Urstein (öffnen) 5412 Puch/Salzburg, Urstein Süd 1 Tel.: +43 / 50-2211-0, https://www.fh-salzburg.ac.at/ Steiermark Ausbildung Tabelle Fachhochschulstudium Industrial Design (öffnen)Bachelorstudium (FH) Fachhochschule Joanneum - Standort Graz (öffnen) 8020 Graz, Alte Poststraße 147, Weitere Adressen: Alte Poststraße 147, 149, 152 + 154; Eggenberger Allee 11 + 13; Eckertstraße 30i Tel.: +43 (0)316 / 54 53-8200, Fax: +43 (0)316 / 54 53-8201, https://www.fh-joanneum.at Ausbildung Tabelle Fachhochschulstudium Ausstellungsdesign (öffnen)Masterstudium (FH) Fachhochschule Joanneum - Standort Graz (öffnen) 8020 Graz, Alte Poststraße 147, Weitere Adressen: Alte Poststraße 147, 149, 152 + 154; Eggenberger Allee 11 + 13; Eckertstraße 30i Tel.: +43 (0)316 / 54 53-8200, Fax: +43 (0)316 / 54 53-8201, https://www.fh-joanneum.at Ausbildung Tabelle Fachhochschulstudium Industrial Design (öffnen)Masterstudium (FH) Fachhochschule Joanneum - Standort Graz (öffnen) 8020 Graz, Alte Poststraße 147, Weitere Adressen: Alte Poststraße 147, 149, 152 + 154; Eggenberger Allee 11 + 13; Eckertstraße 30i Tel.: +43 (0)316 / 54 53-8200, Fax: +43 (0)316 / 54 53-8201, https://www.fh-joanneum.at Wien Ausbildung Tabelle BA/BSc (Hons) Game Art Animation (öffnen)Bachelorstudium (UNI) SAE Institute Wien (öffnen) 1010 Wien, Hohenstaufengasse 6 Tel.: +43 (0)1 / 961 03 03, https://www.sae.edu/aut/ Ausbildung Tabelle BA/BSc (Hons) Visual Effects Animation (öffnen)Bachelorstudium (UNI) SAE Institute Wien (öffnen) 1010 Wien, Hohenstaufengasse 6 Tel.: +43 (0)1 / 961 03 03, https://www.sae.edu/aut/ Ausbildung Tabelle Game Art & 3D Animation Diploma (öffnen)Lehrgang SAE Institute Wien (öffnen) 1010 Wien, Hohenstaufengasse 6 Tel.: +43 (0)1 / 961 03 03, https://www.sae.edu/aut/ Ausbildung Tabelle Visual FX & 3D Animation Diploma (öffnen)Lehrgang SAE Institute Wien (öffnen) 1010 Wien, Hohenstaufengasse 6 Tel.: +43 (0)1 / 961 03 03, https://www.sae.edu/aut/ Weiterbildung Die Weiterbildungs- und Spezialisierungsmöglichkeiten sind grundsätzlich vielfältig und umfassen verschiedenste Bereiche wie E-Learning, Urheberrecht und Technologien für unterschiedliche Anwendungen, z.B:3D-ScantechnikUser Experience DesignDigital BrandingSocial Media MarketingMedia Copywriting (professionelles Verfassen von Werbetexten)360 Grad-Fotografie: Rundum-Blicke auf Produkte oder OrteMedienrecht3D-Modeling und Simulationssoftware\\xa03D-Modeling ist eine Mischung aus Geometrie und Design; es wird häufig genutzt, um Autounfälle zu analysieren, indem das Unfällgeschehen in der digitalen Welt nachstellt wird. Mehr Infos zu Weiterbildungen in der Weiterbildungsdatenbank Aufstieg und Selbstständigkeit Mit mehrjähriger beruflicher Erfahrung ist - je nach Unternehmensstruktur und Qualifikation - der Aufstieg in die Projektleitung oder als TesterIn, Level DesignerIn, ProducerIn, Studio Head oder Creative Director möglich.Es besteht die Möglichkeit zur selbstständigen Berufsausübung im Rahmen eines Gewerbes. Die aktuelle bundeseinheitliche Liste der freien Gewerbe sowie die Liste der reglementierten Gewerbe ist jeweils auf der Website des Bundesministeriums für Digitalisierung und Wirtschaftsstandort abrufbar. Nähere Infos bietet die Website der Wirtschaftskammer Österreich: WKO.  Diese Berufe könnten Sie auch interessieren  FotografIn BMS/BHS BildhauerIn BMS/BHS Kinoservicekraft Hilfs-/Anlernberufe BühnenarbeiterIn Hilfs-/Anlernberufe FilmvorführerIn Hilfs-/Anlernberufe BilleteurIn Hilfs-/Anlernberufe PromoterIn Hilfs-/Anlernberufe KunstmalerIn BMS/BHS Garderobier/Garderobiere Hilfs-/Anlernberufe BildhauerIn Lehre Weitere Berufe aus dem Bereich \"Medien, Grafik, Design, Druck, Kunst, Kunsthandwerk\" anzeigen  Kärnten Niederösterreich Oberösterreich Salzburg Steiermark Wien Ausbildungen nach Art: Masterstudium (UNI) Bachelorstudium (FH) Bachelorstudium (UNI) Masterstudium (FH) Lehrgang  ',\n",
       " 'profession': '3D-DesignerIn',\n",
       " 'url': 'https://www.berufslexikon.at/berufe/3049-3D-DesignerIn/'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the dataset: 3473496\n"
     ]
    }
   ],
   "source": [
    "# count the number of words in the dataset\n",
    "total_words = 0\n",
    "for example in ds[\"train\"]:\n",
    "    total_words += len(example[\"profession\"].split())\n",
    "    total_words += len(example[\"content\"].split())\n",
    "print(f\"Total number of words in the dataset: {total_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this dataset has no validation split, we will create one\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "* https://huggingface.co/LeoLM/leo-hessianai-13b - did not fit on 24GB VRAM\n",
    "    - WARNING:accelerate.big_modeling:You shouldn't move a model when it is dispatched on multiple devices.\n",
    "    - needs FLASH_ATTENTION_SKIP_CUDA_BUILD=TRUE pip install flash-attn==v2.1.1 --no-build-isolation\n",
    "* https://huggingface.co/LeoLM/leo-hessianai-7b\n",
    "* https://huggingface.co/LeoLM/leo-hessianai-7b-chat\n",
    "    - needs FLASH_ATTENTION_SKIP_CUDA_BUILD=TRUE pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# import torch\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     pretrained_model_name_or_path=model_checkpoint,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     trust_remote_code=True  # True for flash-attn2 else False\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# We'll create a tokenizer from model checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)#, use_fast=False)\n",
    "\n",
    "# We'll need padding to have same length sequences in a batch\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define a tokenization function that first concatenates text and target\n",
    "def tokenize_function(example):\n",
    "    # concatenate all texts and tokenize as one sample\n",
    "    # merged = str(example[\"profession\"]) + \" \" + str(example[\"url\"]) + \" \" + str(example[\"content\"])\n",
    "    # print(type(merged))\n",
    "    # print(merged)\n",
    "    merged =  example[\"content\"]\n",
    "    batch = tokenizer(merged, padding='max_length', truncation=True, max_length=128)\n",
    "    batch[\"labels\"] = batch[\"input_ids\"].copy()\n",
    "    return batch\n",
    "\n",
    "# def tokenize_function(example):\n",
    "#     # If the fields are lists of strings, join the strings. Otherwise, use the fields as they are.\n",
    "#     profession = ' '.join(example[\"profession\"]) if isinstance(example[\"profession\"], list) else example[\"profession\"]\n",
    "#     url = ' '.join(example[\"url\"]) if isinstance(example[\"url\"], list) else example[\"url\"]\n",
    "#     content = ' '.join(example[\"content\"]) if isinstance(example[\"content\"], list) else example[\"content\"]\n",
    "\n",
    "#     merged = profession + \" \" + url + \" \" + content\n",
    "#     batch = tokenizer(merged, padding='max_length', truncation=True, max_length=2048)\n",
    "#     batch[\"labels\"] = batch[\"input_ids\"].copy()\n",
    "#     return batch\n",
    "\n",
    "# Apply it on our dataset, and remove the text columns\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True, remove_columns=[\"profession\", \"url\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1122\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 281\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|> EisenbahnbetriebsleiterIn \n",
      " EisenbahnbetriebsleiterIn Berufsbereiche: Büro, Marketing, Finanz, Recht, Sicherheit / Handel, Logistik, Verkehr Ausbildungsform: Kurz-/Spezialausbildung Einstiegsgehalt: Gehalt: nicht bekannt Beruf merken als PDF anzeigen Hinweis Die betriebsinterne Ausbildung zu diesem Beruf kann nur im Rahmen eines aufrechten Dienstverhältnisses absolviert werden. Tätigkeitsmerkmale EisenbahnbetriebsleiterInnen leiten und überw\n"
     ]
    }
   ],
   "source": [
    "# Let's check out one prepared example\n",
    "print(tokenizer.decode(tokenized_datasets[\"train\"][ 1][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## QLORA\n",
    "https://freedium.cfd/https%3A%2F%2Fmedium.com%2F%40newhardwarefound%2Fqlora-with-llama-2-ca1b4bcf26f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/felix/llm/sdc-project-ams/felix/wandb/run-20240117_015507-w07wmnal</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fml-team/leo-hessianai-7b-chat-ams-finetuned/runs/w07wmnal' target=\"_blank\">glowing-wave-17</a></strong> to <a href='https://wandb.ai/fml-team/leo-hessianai-7b-chat-ams-finetuned' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fml-team/leo-hessianai-7b-chat-ams-finetuned' target=\"_blank\">https://wandb.ai/fml-team/leo-hessianai-7b-chat-ams-finetuned</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fml-team/leo-hessianai-7b-chat-ams-finetuned/runs/w07wmnal' target=\"_blank\">https://wandb.ai/fml-team/leo-hessianai-7b-chat-ams-finetuned/runs/w07wmnal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start a new wandb run\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "run = wandb.init(project=f\"{model_name}-ams-finetuned\", job_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPUs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If CUDA is available, use it\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"No GPU available, using the CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the necessary library for loading datasets\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# # Specify the name of the dataset\n",
    "# dataset_name = \"timdettmers/openassistant-guanaco\"\n",
    "\n",
    "# # Load the dataset from the specified name and select the \"train\" split\n",
    "# dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from taprosoft's github: https://github.com/taprosoft/llm_finetuning/blob/efa6df245fee4faf27206d84802d8f58d4b6e77d/inference.py#L20\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    LlamaTokenizer)\n",
    "import torch\n",
    "import os\n",
    "\n",
    "#os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = \"{{your_huggingface_hub_token}}\"\n",
    "\n",
    "def load_hf_model(\n",
    "    base_model,\n",
    "    mode=8,\n",
    "    gradient_checkpointing=False,\n",
    "    device_map=\"auto\",\n",
    "):\n",
    "    kwargs = {\"device_map\": device_map}\n",
    "    if mode == 8:\n",
    "        kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            llm_int8_threshold=0.0,\n",
    "        )\n",
    "    elif mode == 4:\n",
    "        kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "        )\n",
    "    elif mode == 16:\n",
    "        kwargs[\"torch_dtype\"] = torch.float16\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_model, **kwargs)\n",
    "\n",
    "    # setup tokenizer\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "\n",
    "    tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token\n",
    "    tokenizer.padding_side = \"left\"  # Allow batched inference\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from taprosoft's github\n",
    "from dataclasses import dataclass, field\n",
    "import transformers\n",
    "import torch\n",
    "import copy\n",
    "from typing import Dict, Sequence\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "IGNORE_INDEX = -100\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForCausalLM(object):\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "    source_max_len: int\n",
    "    target_max_len: int\n",
    "    train_on_source: bool\n",
    "    predict_with_generate: bool\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        # Extract elements\n",
    "        sources = [f\"{self.tokenizer.bos_token}{example['profession']}\" for example in instances]\n",
    "        targets = [f\"{example['content']}{self.tokenizer.eos_token}\" for example in instances]\n",
    "        # Tokenize\n",
    "        tokenized_sources_with_prompt = self.tokenizer(\n",
    "            sources,\n",
    "            max_length=self.source_max_len,\n",
    "            truncation=True,\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "        tokenized_targets = self.tokenizer(\n",
    "            targets,\n",
    "            max_length=self.target_max_len,\n",
    "            truncation=True,\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "        # Build the input and labels for causal LM\n",
    "        input_ids = []\n",
    "        labels = []\n",
    "        for tokenized_source, tokenized_target in zip(\n",
    "            tokenized_sources_with_prompt['input_ids'],\n",
    "            tokenized_targets['input_ids']\n",
    "        ):\n",
    "            if not self.predict_with_generate:\n",
    "                input_ids.append(torch.tensor(tokenized_source + tokenized_target))\n",
    "                if not self.train_on_source:\n",
    "                    labels.append(\n",
    "                        torch.tensor([IGNORE_INDEX for _ in range(len(tokenized_source))] + copy.deepcopy(tokenized_target))\n",
    "                    )\n",
    "                else:\n",
    "                    labels.append(torch.tensor(copy.deepcopy(tokenized_source + tokenized_target)))\n",
    "            else:\n",
    "                input_ids.append(torch.tensor(tokenized_source))\n",
    "        # Apply padding\n",
    "        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        labels = pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX) if not self.predict_with_generate else None\n",
    "        data_dict = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask':input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        }\n",
    "        if labels is not None:\n",
    "            data_dict['labels'] = labels\n",
    "        return data_dict\n",
    "\n",
    "data_collator = DataCollatorForCausalLM(\n",
    "        tokenizer=tokenizer,\n",
    "        source_max_len=280,\n",
    "        target_max_len=512,\n",
    "        train_on_source=False,\n",
    "        predict_with_generate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['content', 'profession', 'url'],\n",
      "    num_rows: 1122\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "# #reduce dataset size for testing\n",
    "# dataset = dataset.select(range(100))\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import peft\n",
    "\n",
    "# COPIED FROM https://github.com/artidoro/qlora/blob/main/qlora.py\n",
    "def print_trainable_parameters(model, use_4bit=False):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        # if using DS Zero 3 and the weights are initialized empty\n",
    "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
    "            num_params = param.ds_numel\n",
    "\n",
    "        all_param += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "    if use_4bit:\n",
    "        trainable_params /= 2\n",
    "    print(\n",
    "        f\"all params: {all_param:,d} || trainable params: {trainable_params:,d} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# COPIED FROM https://github.com/artidoro/qlora/blob/main/qlora.py\n",
    "def find_all_linear_names(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, bnb.nn.Linear4bit):\n",
    "            names = name.split(\".\")\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if \"lm_head\" in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove(\"lm_head\")\n",
    "    return list(lora_module_names)\n",
    "\n",
    "\n",
    "def create_peft_model(model, gradient_checkpointing=True, bf16=True):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_kbit_training,\n",
    "    )\n",
    "    from peft.tuners.lora import LoraLayer\n",
    "\n",
    "    # prepare int-4 model for training\n",
    "    model = prepare_model_for_kbit_training(\n",
    "        model, use_gradient_checkpointing=gradient_checkpointing\n",
    "    )\n",
    "    if gradient_checkpointing:\n",
    "        model.gradient_checkpointing_enable()\n",
    "\n",
    "    # get lora target modules\n",
    "    modules = find_all_linear_names(model)\n",
    "    print(f\"Found {len(modules)} modules to quantize: {modules}\")\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        target_modules=modules,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "    # pre-process the model by upcasting the layer norms in float 32 for\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, LoraLayer):\n",
    "            if bf16:\n",
    "                module = module.to(torch.bfloat16)\n",
    "        if \"norm\" in name:\n",
    "            module = module.to(torch.float32)\n",
    "        if \"lm_head\" in name or \"embed_tokens\" in name:\n",
    "            if hasattr(module, \"weight\"):\n",
    "                if bf16 and module.weight.dtype == torch.float32:\n",
    "                    module = module.to(torch.bfloat16)\n",
    "\n",
    "    model.print_trainable_parameters()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.32s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 modules to quantize: ['q_proj', 'o_proj', 'gate_proj', 'down_proj', 'k_proj', 'up_proj', 'v_proj']\n",
      "trainable params: 159,907,840 || all params: 6,899,372,032 || trainable%: 2.3177158625209793\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# Defining the model\n",
    "model_name = model_checkpoint\n",
    "\n",
    "\n",
    "model, tokenizer = load_hf_model(\n",
    "    model_name,\n",
    "    mode=4,\n",
    "    gradient_checkpointing=False,\n",
    "    device_map='auto')\n",
    "\n",
    "\n",
    "\n",
    "# create peft config\n",
    "model = create_peft_model(\n",
    "    model, gradient_checkpointing=False, bf16=False\n",
    ")\n",
    "\n",
    "# get all linear layer names\n",
    "modules = find_all_linear_names(model)\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "# Define training args\n",
    "output_dir = \"./results\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    bf16=False,  # Use BF16 if available\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    optim=\"paged_adamw_8bit\", #\"adamw_torch\" if not mode = 4,8\n",
    "    gradient_checkpointing=False,\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = next(model.parameters()).device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1122' max='1122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1122/1122 57:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.272300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.251800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.972400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.044600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.121500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.992900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.911400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.083100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.061400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.063800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.163600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.997300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.073400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.909100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.973900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.950500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.187400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.073400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.077500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.914600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.954700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.827300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.975400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.901300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.949900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.908700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.892200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.907300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.085900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.913900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.972500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.892200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.980800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.884400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.811000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.924400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.987700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.713200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.846400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.969500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.771900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.887400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.906400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.860700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.893400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.872300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.989400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.881900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.829300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.855500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.935200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.949500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.880600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.831400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.895100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.887700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "except RuntimeError as e:\n",
    "    if \"CUBLAS_STATUS_EXECUTION_FAILED\" in str(e):\n",
    "        print(\"CUDA error: Out of memory or hardware issue. Trying to free up memory.\")\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        raise e  # Re-raise the exception if it's not a CUDA error\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(f\"{model_name}-ams-finetuned\")\n",
    "\n",
    "#full 1120 epochs 57m 22.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()\n",
    "# #save the model\n",
    "# trainer.save_model(f\"{model_name}-ams-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# model is the quantized model loaded using load_hf_model in a previous step\n",
    "model = PeftModel.from_pretrained(model, f\"{model_name}-ams-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systemDies ist eine Unterhaltung zwischen einem intelligenten, hilfsbereitem KI-Assistenten und einem Nutzer. Der Assistent gibt ausführliche, hilfreiche und ehrliche Antworten. \n",
      "     user\n",
      "Hallo, ich bin 18 Jahre alt, arbeite gerne mit Tieren und bin sehr kreativ. Ich suche einen Beruf, der mir Spaß macht und bei dem ich mich weiterentwickeln kann. Ich war nicht so gut in der Schule. Bitte sag mir was für Berufe in Frage kämen, welche Ausbildung ich benötige und mit welchem Gehalt ich rechnen kann. \n",
      " assistant\n",
      "Es tut mir leid, dass du nicht so gut in der Schule warst. Ich verstehe, dass du einen Beruf suchst, der dir Spaß macht und bei dem du dich weiterentwickeln kannst. Hier sind einige Berufe, die deinen Interessen und Fähigkeiten entsprechen könnten:\n",
      "\n",
      "1. Tierpfleger: Du liebst Tiere und möchtest in einem kreativen Bereich arbeiten. Tierpfleger sind dafür verantwortlich, Tiere zu pflegen, indem sie sie baden, trimmen und pflegen. Die meisten Bundesstaaten erfordern einen Abschluss von einer Tierpflegeschule, die 6 bis 12 Monate dauert. Tierpfleger verdienen im Durchschnitt zwischen $20.000 und $40.000 pro Jahr.\n",
      "\n",
      "2. Grafikdesigner: Du bist kreativ und hast eine Vorliebe für Kunst. Grafikdesigner erstellen visuelle Konzepte für verschiedene Medien wie Websites, Anzeigen, Verpackungen und Bücher. Die meisten Grafikdesigner haben einen Abschluss in Grafikdesign oder verwandten Bereichen wie Kommunikationsdesign oder visueller Kunst. Das Gehalt für Grafikdesigner liegt im Durchschnitt zwischen $40.000 und $100.000 pro Jahr.\n",
      "\n",
      "3. Tierarztassistent: Du liebst Tiere und möchtest in einem medizinischen Bereich arbeiten. Tierarztassistenten arbeiten mit Tierärzten zusammen, um Tiere zu untersuchen, zu behandeln und zu pflegen. Die meisten Tierarztassistenten haben eine Ausbildung von ein paar Monaten bis zu einem Jahr. Tierarztassistenten verdienen im Durchschnitt zwischen $20.000 und $40.000 pro Jahr.\n",
      "\n",
      "Diese Berufe könnten gut zu dir passen und bieten dir die Möglichkeit, Spaß zu haben und dich in Bereichen zu entwickeln, die du liebst. \n",
      " </s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "# sequences = [\"<s>[INST] <<SYS>> You are a helpful assistant. <</SYS>>\\\n",
    "# Extract the place names from the given sentence. [\\INST]\\n\\\n",
    "# The capital of the United States is Washington D.C.\"]\n",
    "\n",
    "prompt = \"Hallo, ich bin 18 Jahre alt, arbeite gerne mit Tieren und bin sehr kreativ. Ich suche einen Beruf, der mir Spaß macht und bei dem ich mich weiterentwickeln kann. Ich war nicht so gut in der Schule. Bitte sag mir was für Berufe in Frage kämen, welche Ausbildung ich benötige und mit welchem Gehalt ich rechnen kann.\"\n",
    "\n",
    "sequences = [f\"<|im_start|>system\\\n",
    "Dies ist eine Unterhaltung zwischen einem intelligenten, hilfsbereitem KI-Assistenten und einem Nutzer. Der Assistent gibt ausführliche, hilfreiche und ehrliche Antworten.<|im_end|>\\n\\\n",
    "    <|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"]\n",
    "\n",
    "\n",
    "inputs = tokenizer(sequences, padding=True, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs, \n",
    "    generation_config=GenerationConfig(\n",
    "        do_sample=True,\n",
    "        max_new_tokens=512,\n",
    "        top_p=0.99,\n",
    "        temperature=1e-8,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systemDies ist eine Unterhaltung zwischen einem intelligenten, hilfsbereitem KI-Assistenten und einem Nutzer. Der Assistent gibt ausführliche, hilfreiche und ehrliche Antworten. \n",
      "     user\n",
      "Erkläre mir bitte wie man von Wien nach München kommt \n",
      " assistant\n",
      "Natürlich, gerne helfe ich dir dabei, deine Reise von Wien nach München zu planen. Hier sind einige Optionen, die du in Betracht ziehen kannst:\n",
      "\n",
      "1. Zug: Du kannst den Zug nehmen. Es gibt mehrere Züge von Wien nach München, und du kannst die Verfügbarkeit und die Fahrpläne einfach über die Website der Österreichischen Bundesbahnen (ÖBB) oder der Deutschen Bahn überprüfen. Die Fahrt dauert etwa 4 Stunden.\n",
      "\n",
      "2. Auto: Wenn du eine längere Reise planst, bietet es sich möglicherweise an, dein eigenes Auto mitzubringen. Von Wien aus kannst du in etwa 4 Stunden nach München fahren. Alternativ kannst du ein Auto von einem Autovermietungsunternehmen mieten.\n",
      "\n",
      "3. Flugzeug: Du kannst einen Flug von Wien nach München nehmen. Viele Fluggesellschaften bedienen diese Strecke, und du kannst online nach Verfügbarkeit und Preisen suchen. Der Flug dauert etwa 1 Stunde.\n",
      "\n",
      "4. Bus: Alternativ kannst du einen Bus von Wien nach München nehmen. Mehrere Busunternehmen betreiben diese Strecke, und du kannst online nach Verfügbarkeit und Preisen suchen. Die Fahrt dauert etwa 4 Stunden.\n",
      "\n",
      "Ich hoffe, dass diese Optionen dir helfen, deine Reise von Wien nach München zu planen. Lass es mich wissen, wenn du weitere Hilfe benötigst. \n",
      " </s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "# sequences = [\"<s>[INST] <<SYS>> You are a helpful assistant. <</SYS>>\\\n",
    "# Extract the place names from the given sentence. [\\INST]\\n\\\n",
    "# The capital of the United States is Washington D.C.\"]\n",
    "\n",
    "prompt = \"Erkläre mir bitte wie man von Wien nach München kommt\"\n",
    "\n",
    "sequences = [f\"<|im_start|>system\\\n",
    "Dies ist eine Unterhaltung zwischen einem intelligenten, hilfsbereitem KI-Assistenten und einem Nutzer. Der Assistent gibt ausführliche, hilfreiche und ehrliche Antworten.<|im_end|>\\n\\\n",
    "    <|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"]\n",
    "\n",
    "\n",
    "inputs = tokenizer(sequences, padding=True, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs, \n",
    "    generation_config=GenerationConfig(\n",
    "        do_sample=True,\n",
    "        max_new_tokens=512,\n",
    "        top_p=0.99,\n",
    "        temperature=1e-8,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systemDies ist eine Unterhaltung zwischen einem intelligenten, hilfsbereitem KI-Assistenten und einem Nutzer. Der Assistent gibt ausführliche, hilfreiche und ehrliche Antworten. \n",
      "     user\n",
      "Erkläre mir bitte wie man von Wien nach München kommt \n",
      " assistant\n",
      "Natürlich, gerne helfe ich dir dabei, deine Reise von Wien nach München zu planen. Hier sind einige Optionen, die du in Betracht ziehen kannst:\n",
      "\n",
      "1. Zug: Du kannst den Zug nehmen. Es gibt mehrere Züge von Wien nach München, und du kannst die Verfügbarkeit und die Fahrpläne einfach über die Website der Österreichischen Bundesbahnen (ÖBB) oder der Deutschen Bahn überprüfen. Die Fahrt dauert etwa 4 Stunden.\n",
      "\n",
      "2. Auto: Wenn du eine längere Reise planst, bietet es sich möglicherweise an, dein eigenes Auto mitzubringen. Von Wien aus kannst du in etwa 4 Stunden nach München fahren. Alternativ kannst du ein Auto von einem Autovermietungsunternehmen mieten.\n",
      "\n",
      "3. Flugzeug: Du kannst einen Flug von Wien nach München nehmen. Viele Fluggesellschaften bedienen diese Strecke, und du kannst online nach Verfügbarkeit und Preisen suchen. Der Flug dauert etwa 1 Stunde.\n",
      "\n",
      "4. Bus: Alternativ kannst du einen Bus von Wien nach München nehmen. Mehrere Busunternehmen betreiben diese Strecke, und du kannst online nach Verfügbarkeit und Preisen suchen. Die Fahrt dauert etwa 4 Stunden.\n",
      "\n",
      "Ich hoffe, dass diese Optionen dir helfen, deine Reise von Wien nach München zu planen. Lass es mich wissen, wenn du weitere Hilfe benötigst. \n",
      " </s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "# sequences = [\"<s>[INST] <<SYS>> You are a helpful assistant. <</SYS>>\\\n",
    "# Extract the place names from the given sentence. [\\INST]\\n\\\n",
    "# The capital of the United States is Washington D.C.\"]\n",
    "\n",
    "prompt = \"Erkläre mir bitte wie man von Wien nach München kommt\"\n",
    "\n",
    "sequences = [f\"<|im_start|>system\\\n",
    "Dies ist eine Unterhaltung zwischen einem intelligenten, hilfsbereitem KI-Assistenten und einem Nutzer. Der Assistent gibt ausführliche, hilfreiche und ehrliche Antworten.<|im_end|>\\n\\\n",
    "    <|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"]\n",
    "\n",
    "\n",
    "inputs = tokenizer(sequences, padding=True, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs, \n",
    "    generation_config=GenerationConfig(\n",
    "        do_sample=True,\n",
    "        max_new_tokens=512,\n",
    "        top_p=0.99,\n",
    "        temperature=1e-8,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Flash Attention installed\n",
      ">>>> Flash RoPE installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.44s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '<|im_start|>user\\nErkläre mir wie die Fahrradwegesituation in Hamburg ist.<|im_end|>\\n<|im_start|>assistant\\nAls KI habe ich keine persönlichen Erfahrungen mit den Fahrradwegesituationen in verschiedenen Städten und Ländern. Ich kann jedoch allgemeine Informationen zu den Fahrradwegen in Hamburg finden und dir zur Verfügung stellen. \\n'}]\n"
     ]
    }
   ],
   "source": [
    "# from transformers import pipeline\n",
    "# import torch\n",
    "\n",
    "# system_prompt = \"\"\"<|im_start|>system\n",
    "# Dies ist eine Unterhaltung zwischen einem intelligenten, hilfsbereitem KI-Assistenten und einem Nutzer.\n",
    "# Der Assistent gibt ausführliche, hilfreiche und ehrliche Antworten.<|im_end|>\n",
    "\n",
    "# \"\"\"\n",
    "# prompt_format = \"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "# prompt = \"Erkläre mir wie die Fahrradwegesituation in Hamburg ist.\"\n",
    "\n",
    "# generator = pipeline(model=model_name, device=\"cuda\", torch_dtype=torch.float16, trust_remote_code=True) # True for flash-attn2 else False\n",
    "# print(generator(prompt_format.format(prompt=prompt), do_sample=True, top_p=0.95, max_length=8192))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers.logging.set_verbosity_error() # suppress tokenizer warnings\n",
    "\n",
    "# prefix = \"Hilf bei der Suche nach einem Beruf:\"\n",
    "\n",
    "# prompts = [\n",
    "#     \"Ich bin 15 Jahre alt, gut im Umgang mit Menschen und möchte gerne einen Beruf erlernen, in dem ich viel mit Menschen zu tun habe.\",\n",
    "#     \"Ich bin 30 Jahre alt und mag Tier sehr gerne. Ich möchte gerne einen Beruf erlernen, in dem ich viel mit Tieren zu tun habe.\",\n",
    "#     \"Ich bin 19 und möchte etwas technisches machen. Ich bin sehr gut in Mathe und Physik.\",\n",
    "# ]\n",
    "\n",
    "# table = wandb.Table(columns=[\"prompt\", \"generated\", \"input_tokens\", \"generated_tokens\"])\n",
    "\n",
    "# for prompt in prompts:\n",
    "#     # encode the prompt and generate text until the output length (which includes the context length) reaches 50\n",
    "#     input_ids = tokenizer.encode(prefix + prompt, return_tensors='pt').to(device)\n",
    "#     output = model.generate(input_ids, max_length=128, num_beams=5, early_stopping=True)\n",
    "#     generated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#     table.add_data(prompt, generated, len(input_ids[0]), len(output[0]))\n",
    "    \n",
    "# wandb.log({\"generated\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
