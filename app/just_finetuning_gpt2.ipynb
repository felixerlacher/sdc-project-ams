{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/llm/ChatTable/new_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfelix-ml\u001b[0m (\u001b[33mfml-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/felix/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelWithLMHead\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import transformers\n",
    "transformers.set_seed(42)\n",
    "\n",
    "import wandb\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'just_finetuning_gpt2.ipynb'\n",
    "wandb.login(key=\"247b3da94c9b88bd5e990f1d94799ca3ded57d6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your JSON file\n",
    "file_path = 'data/berufslexikon_regex_cleaned.json'\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset('json', data_files=file_path)\n",
    "\n",
    "# Specify the model checkpoint\n",
    "model_checkpoint = \"dbmdz/german-gpt2\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.berufslexikon.at/berufe/3049-3D-DesignerIn/',\n",
       " 'profession': '3D-DesignerIn',\n",
       " 'content': '3D-DesignerIn\\nZurück\\n3D-DesignerIn\\nBerufsbereiche:\\nMedien, Grafik, Design, Druck, Kunst, Kunsthandwerk\\nAusbildungsform: Uni/FH/PH\\nEinstiegsgehalt lt. KV:\\nGehalt:\\n€ 2.210,- bis € 2.730,- *\\n3D-DesignerInnen entwerfen, erstellen und programmieren komplexe, dreidimensionale digitale Objekte. Da sind z.B. Figuren für Videospiele und Filme, Grafiken, bewegte Bilder oder räumlich wirkende Darstellungen. Sie animieren auch Standbilder aus 3D-Scans. Außerdem programmieren sie interaktive 3D-Echtzeitgrafiken, zum Beispiel ein dreidimensionales Modell einer realen Szene (Virtuelle Realität).Digitale Objekte dienen zur Visualisierung in allen möglichen Bereichen wie Architektur, Raumplanung, Verkehr und Sport oder für die Visualisierung in technischen Bereichen. Die DesignerInnen nutzen 3D-Modeling-Software (z.B. AutoCad) und Simulationssoftware für interaktive 3D-Echtzeitgrafiken. Besondere Bedeutung hat die Visualisierung von Objekten auch für das E-Learning sowie für Orientierungssysteme, Modelabels und technische Dokumentationen.Typische Tätigkeiten sind z.B:Mitwirkung an der Entwicklung von Drehbüchern und StorylinesZeichnungen und Skizzen anfertigenModellieren von 3D-Objekten für Filme, Musikvideos oder ComputerspieleGestalten von Grafiken für Social Media KampagnenGestalten von 360-Grad-Videos für die Werbe- und SpielindustrieVisualisierung von Produkten für ProduktpräsentationenAnimieren von Figuren und ObjektenErstellen von virtuellen Räumen, Architektur- und Landschaftsvisualisierungen\\nSiehe auch:\\nMedieninformatikerIn\\n(UNI/FH/PH) \\nIndustrial DesignerIn\\n(UNI/FH/PH) \\nGame DesignerIn\\n(UNI/FH/PH) \\nAnforderungen\\nEine innovative Ideenfindung und ein gewisses Maß an künstlerischer Begabung sind von Vorteil. Die Arbeiten erfolgen manchmal unter Zeitdruck, wobei KundInnen trotzdem eine detailorientierte Arbeit einfordern.Interesse an Technik: Bildverarbeitung, Audio- und VideotechnikBlick für DetailsGutes SehvermögenRasche AuffassungsgabeStrukturiertes ArbeitenRäumliches VorstellungsvermögenGutes Zeitmanagement\\xa0Je nach Branche sind auch andere Belange wichtig, etwa ein Interesse an Kunst, Kultur und Design (z.B. für Arbeiten in der Retail- oder Luxusgüter Industrie).\\nBeschäftigungsmöglichkeiten\\n3D-DesignerInnen arbeiten in der Pre- und Postproduktion im Bereich Game Design (Storyboarding, Schnitt). Beschäftigungsmöglichkeiten eröffnen sich zum Teil in der Konsumgüterindustrie in einer Design-Abteilung oder im Umfeld der Marketing-Abteilung. Funktionales 3D-Design wird in fast jeder Branche angewandt, auch in den technischen Bereichen, in der Architektur, der Geoinformation und in der Unfallanalytik. Aufgabenfelder bestehen in den Unternehmen der unterschiedlichsten Branchen, z.B:Spezialisierte Design-BürosMultimedia-AgenturenSportartikehersteller: Markenlogos, WerbematerialGesundheitssektor: Animierte InfografikenIndustrie: Technische VisualisierungFahrzeugtechnik: Produkt-KonfiguratorenWerbebranche: Interaktive Werbeanzeigen, Online-WerbungSocial Media und Webdesign: Visuelle Konzepte für BlogsOnlinehandel: Interaktive ProduktpräsentationProduktdesign: Prototyp-VisualisierungArchitektur: Rundgänge, pysikalische Simulation von LichtMedizin: Funktionsweise von Werkzeugen verdeutlichenTourismus/Kultur: Interaktive Webkarten, virtuelle Museen\\nBerufsaussichten\\nBesondere Chancen zeichnen sich für die AbsolventInnen ab, die kombinierte Kenntnisse in Bezug auf Technik, Gestaltung und Organisation optimal einsetzen können. Vor allem ist die weltweite Nutzung von Virtual Reality (VR) stark gestiegen.Virtual Reality ist die blickpunktabhängige Echtzeitberechnung von 3D-Grafik (computergesteuerte Bilder in 3D). Das ermöglicht es, durch eine computergenerierte, künstliche räumliche Umgebung zu navigieren und mit dieser zu interagieren. Mit VR kann man z.B. üben, in einer Stresssituation eine Rede zu halten. Zum Unterschied von normaler Video-Technik werden für VR-Videos besondere Kameras benötigt, die aus verschiedensten Winkeln filmen. Im Unterschied dazu überlappt Augmented Reality (AR) das in der Wirklichkeit gesehene Bild oder Szene mit einer Simulation.Typische 3D-Anwendungen werden zunehmend auch in der Stadtplanung eingesetzt sowie in der Außen- und Innenarchitektur und Möbelausstattung. In der 3D-Realität können auch Veränderungen vorab visualisiert, analysiert und optimiert werden.3D-Design steht in Zusammenhang mit Game Design und spielt verstärkt auch bei Themen wie Business Communications oder Einsatzkräftetraining für Feuerwehren und Katastrophendienste eine Rolle.\\n3D-Design ist eine Kombination aus Kunst und Technik visuelles Design und Videobearbeitung. Eine Grundlage kann z.B. ein Studium im Bereich Game-Design, Grafikdesign (Motion Graphics), Multimedia Design oder Mediendesign bieten. Beispiele für Ausbildungen:Medieninformatik und Visual Computing (Bachelor): TU WienMedientechnik und –design (Bachelor): FH Oberösterreich Game Engineering und Simulation (Master): FH Technikum Wien Game Art & 3D Animation (Diploma): SAE Institute WienVisual Effects Animation (Bachelor with Honours): SAE Institute Wien Digital Art–Compositing (Master): Uni für Musik und darstellende Kunst, Wien\\nWeiterbildung\\nDie Weiterbildungs- und Spezialisierungsmöglichkeiten sind grundsätzlich vielfältig und umfassen verschiedenste Bereiche wie E-Learning, Urheberrecht und Technologien für unterschiedliche Anwendungen, z.B:3D-ScantechnikUser Experience DesignDigital BrandingSocial Media MarketingMedia Copywriting (professionelles Verfassen von Werbetexten)360 Grad-Fotografie: Rundum-Blicke auf Produkte oder OrteMedienrecht3D-Modeling und Simulationssoftware\\xa03D-Modeling ist eine Mischung aus Geometrie und Design; es wird häufig genutzt, um Autounfälle zu analysieren, indem das Unfällgeschehen in der digitalen Welt nachstellt wird.\\nMehr Infos zu Weiterbildungen in der Weiterbildungsdatenbank\\nAufstieg und Selbstständigkeit\\nMit mehrjähriger beruflicher Erfahrung ist - je nach Unternehmensstruktur und Qualifikation - der Aufstieg in die Projektleitung oder als TesterIn, Level DesignerIn, ProducerIn, Studio Head oder Creative Director möglich.Es besteht die Möglichkeit zur selbstständigen Berufsausübung im Rahmen eines Gewerbes. Die aktuelle bundeseinheitliche Liste der freien Gewerbe sowie die Liste der reglementierten Gewerbe ist jeweils auf der Website des Bundesministeriums für Digitalisierung und Wirtschaftsstandort abrufbar. Nähere Infos bietet die Website der Wirtschaftskammer Österreich: WKO.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the dataset: 1021826\n"
     ]
    }
   ],
   "source": [
    "# count the number of words in the dataset\n",
    "total_words = 0\n",
    "for example in ds[\"train\"]:\n",
    "    total_words += len(example[\"profession\"].split())\n",
    "    total_words += len(example[\"content\"].split())\n",
    "print(f\"Total number of words in the dataset: {total_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this dataset has no validation split, we will create one\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/llm/ChatTable/new_env/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1564: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds[\"train\"][1][\"profession\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create a tokenizer from model checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)#, use_fast=False)\n",
    "\n",
    "# We'll need padding to have same length sequences in a batch\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define a tokenization function that first concatenates text and target\n",
    "def tokenize_function(example):\n",
    "    # concatenate all texts and tokenize as one sample\n",
    "    # merged = str(example[\"profession\"]) + \" \" + str(example[\"url\"]) + \" \" + str(example[\"content\"])\n",
    "    # print(type(merged))\n",
    "    # print(merged)\n",
    "    merged =  example[\"content\"]\n",
    "    batch = tokenizer(merged, padding='max_length', truncation=True, max_length=128)\n",
    "    batch[\"labels\"] = batch[\"input_ids\"].copy()\n",
    "    return batch\n",
    "\n",
    "# def tokenize_function(example):\n",
    "#     # If the fields are lists of strings, join the strings. Otherwise, use the fields as they are.\n",
    "#     profession = ' '.join(example[\"profession\"]) if isinstance(example[\"profession\"], list) else example[\"profession\"]\n",
    "#     url = ' '.join(example[\"url\"]) if isinstance(example[\"url\"], list) else example[\"url\"]\n",
    "#     content = ' '.join(example[\"content\"]) if isinstance(example[\"content\"], list) else example[\"content\"]\n",
    "\n",
    "#     merged = profession + \" \" + url + \" \" + content\n",
    "#     batch = tokenizer(merged, padding='max_length', truncation=True, max_length=2048)\n",
    "#     batch[\"labels\"] = batch[\"input_ids\"].copy()\n",
    "#     return batch\n",
    "\n",
    "# Apply it on our dataset, and remove the text columns\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True, remove_columns=[\"profession\", \"url\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1122\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 281\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EisenbahnbetriebsleiterIn\n",
      "Zurück\n",
      "EisenbahnbetriebsleiterIn\n",
      "Berufsbereiche:\n",
      "Büro, Marketing, Finanz, Recht, Sicherheit\n",
      "/ Handel, Logistik, Verkehr\n",
      "Ausbildungsform: Kurz-/Spezialausbildung\n",
      "Einstiegsgehalt:\n",
      "Gehalt:\n",
      "nicht bekannt\n",
      "EisenbahnbetriebsleiterInnen leiten und überwachen die sicherheitsrelevanten Prozesse in einem Eisenbahnunternehmen und tragen die Verantwortung für einen sicheren und rechtmäßigen Eisenbahnbetrieb. Sie sind dafür verantwortlich, dass die Züge, Bahnanlagen und Bauwerke einwandfrei funktionieren.\n",
      "Im Rahmen ihrer Tätigkeit kennen EisenbahnbetriebsleiterInnen die allgemein rechtlichen Grundsätze des Eisenbahnwesens und übernehmen die Verantwortung der Betriebssicherheit und Instandhaltung von\n"
     ]
    }
   ],
   "source": [
    "# Let's check out one prepared example\n",
    "print(tokenizer.decode(tokenized_datasets[\"train\"][ 1][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/felix/llm/sdc-project-ams/felix/wandb/run-20240118_192855-bddb32ot</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fml-team/german-gpt2-ams-finetune/runs/bddb32ot' target=\"_blank\">kind-haze-9</a></strong> to <a href='https://wandb.ai/fml-team/german-gpt2-ams-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fml-team/german-gpt2-ams-finetune' target=\"_blank\">https://wandb.ai/fml-team/german-gpt2-ams-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fml-team/german-gpt2-ams-finetune/runs/bddb32ot' target=\"_blank\">https://wandb.ai/fml-team/german-gpt2-ams-finetune/runs/bddb32ot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start a new wandb run\n",
    "run = wandb.init(project=\"german-gpt2-ams-finetune\", job_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPUs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If CUDA is available, use it\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"No GPU available, using the CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-ams-finetuned\",\n",
    "    report_to=\"wandb\", # we need one line to track experiments in wandb\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    #no_cuda=False, # force cpu use, will be renamed `use_cpu`\n",
    "    save_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use HF Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='705' max='705' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [705/705 04:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.224200</td>\n",
       "      <td>1.213453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.011600</td>\n",
       "      <td>1.199784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.644700</td>\n",
       "      <td>1.226781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.717800</td>\n",
       "      <td>1.268782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>1.320830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=705, training_loss=0.9177215188107593, metrics={'train_runtime': 247.0557, 'train_samples_per_second': 22.707, 'train_steps_per_second': 2.854, 'total_flos': 366462074880000.0, 'train_loss': 0.9177215188107593, 'epoch': 5.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move model to GPU\n",
    "model.to(device)\n",
    "# Let's train!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "#trainer.save_model(f\"{model_name}-ams-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_error() # suppress tokenizer warnings\n",
    "\n",
    "#load model from pretrained\n",
    "model_checkpoint = \"./german-gpt2-ams-finetuned/checkpoint-564\"\n",
    "model = AutoModelWithLMHead.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Identify the device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "prefix = \"Hilf bei der Suche nach einem Beruf:\"\n",
    "\n",
    "prompts = [\n",
    "    \"Ich bin 15 Jahre alt, gut im Umgang mit Menschen und möchte gerne einen Beruf erlernen, in dem ich viel mit Menschen zu tun habe.\",\n",
    "    \"Ich bin 30 Jahre alt und mag Tier sehr gerne. Ich möchte gerne einen Beruf erlernen, in dem ich viel mit Tieren zu tun habe.\",\n",
    "    \"Ich bin 19 und möchte etwas technisches machen. Ich bin sehr gut in Mathe und Physik.\",\n",
    "]\n",
    "\n",
    "table = wandb.Table(columns=[\"prompt\", \"generated\", \"input_tokens\", \"generated_tokens\"])\n",
    "\n",
    "for prompt in prompts:\n",
    "    # encode the prompt and generate text until the output length (which includes the context length) reaches 50\n",
    "    input_ids = tokenizer.encode(prefix + prompt, return_tensors='pt').to(device)\n",
    "    output = model.generate(input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
    "    generated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    table.add_data(prompt, generated, len(input_ids[0]), len(output[0]))\n",
    "    \n",
    "wandb.log({\"generated\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▂▁▃▅█</td></tr><tr><td>eval/runtime</td><td>▁▃█▃▄</td></tr><tr><td>eval/samples_per_second</td><td>█▆▁▆▅</td></tr><tr><td>eval/steps_per_second</td><td>█▆▁▆▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▆▅▅▅▅▄▅▄▄▃▄▄▄▂▄▃▂▂▂▂▃▁▂▂▂▁▂▂▂▁▁▁▂▂▁▁▂</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.32083</td></tr><tr><td>eval/runtime</td><td>3.4477</td></tr><tr><td>eval/samples_per_second</td><td>81.504</td></tr><tr><td>eval/steps_per_second</td><td>10.442</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>705</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3915</td></tr><tr><td>train/total_flos</td><td>366462074880000.0</td></tr><tr><td>train/train_loss</td><td>0.91772</td></tr><tr><td>train/train_runtime</td><td>247.0557</td></tr><tr><td>train/train_samples_per_second</td><td>22.707</td></tr><tr><td>train/train_steps_per_second</td><td>2.854</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-haze-9</strong> at: <a href='https://wandb.ai/fml-team/german-gpt2-ams-finetune/runs/bddb32ot' target=\"_blank\">https://wandb.ai/fml-team/german-gpt2-ams-finetune/runs/bddb32ot</a><br/> View job at <a href='https://wandb.ai/fml-team/german-gpt2-ams-finetune/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMTUzNjQwNg==/version_details/v1' target=\"_blank\">https://wandb.ai/fml-team/german-gpt2-ams-finetune/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMTUzNjQwNg==/version_details/v1</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240118_192855-bddb32ot/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
